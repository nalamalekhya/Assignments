import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
import nltk
from nltk.corpus import stopwords
import string

# Download stopwords for preprocessing (if not already downloaded)
nltk.download('stopwords')

# Read data from Excel file (replace 'webtoon.xlsx' with your file path)
df = pd.read_excel('/webtoon.xlsx')

# Check the first few rows to ensure the data is loaded correctly
print("Initial Data:")
print(df.head())

# Check unique categories and their counts
print("\nCategory Distribution:")
print(df['category'].value_counts())

# Text preprocessing: lowercase, remove punctuation and stopwords
def preprocess_text(text):
    stop_words = set(stopwords.words('english'))
    text = text.lower()  # convert to lowercase
    text = text.translate(str.maketrans('', '', string.punctuation))  # remove punctuation
    words = [word for word in text.split() if word not in stop_words]  # remove stopwords
    return ' '.join(words)

# Apply preprocessing to the descriptions
df['description_cleaned'] = df['description'].apply(preprocess_text)

# Check cleaned data
print("\nCleaned Descriptions Sample:")
print(df['description_cleaned'].head(10))

# Vectorize text descriptions using TF-IDF with a limit on features
vectorizer = TfidfVectorizer(max_features=1000)  # Limit to the top 1000 features
X = vectorizer.fit_transform(df['description_cleaned'])

# Labels (categories)
y = df['category']

# Split data into training and testing sets (70% training, 30% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize and train a Decision Tree Classifier
classifier = DecisionTreeClassifier()
classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"\nModel Accuracy: {accuracy * 100:.2f}%")

# Display classification report for detailed metrics
print("\nClassification Report:")
print(classification_report(y_test, y_pred, zero_division=1))

# Show predictions compared to actual categories for each test case
results = pd.DataFrame({'Description': df['description'][y_test.index], 'Actual': y_test, 'Predicted': y_pred})
print("\nSample Predictions:")
print(results)
